{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaIIen/101Alphas/blob/main/rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pip"
      ],
      "metadata": {
        "id": "-dLkwcfTC0aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiYj2g92kQFp"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
        "!pip install git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "!pip install talib-binary\n",
        "!pip install tushare\n",
        "!git clone https://github.com/FaIIen/101Alphas.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HolsTo1h2HX_"
      },
      "source": [
        "# 环境初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_m9pjKskXNm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "import gym\n",
        "import yfinance as yf\n",
        "import itertools\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import torch as th\n",
        "import tushare as ts\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "ts.set_token('287ca801de30d29b564d0981a825f01062fb7e7888f163bc62170438')\n",
        "\n",
        "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "from tqdm import tqdm\n",
        "from stable_baselines3 import PPO, SAC\n",
        "\n",
        "sys.path.insert(0,'/content/101Alphas')\n",
        "import utils as u\n",
        "import feature_generation as fg\n",
        "\n",
        "if not os.path.exists(\"./\" + \"tb_log\"):\n",
        "  os.makedirs(\"./\" + \"tb_log\")\n",
        "\n",
        "seed = 29\n",
        "set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_EGB5vdj19F"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q86KC4n9juWF"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir tb_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrSFLk5uuKph"
      },
      "source": [
        "# 数据下载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AshNU6Vr7I0z"
      },
      "outputs": [],
      "source": [
        "cnstock = [\"000002.sz\"]\n",
        "\n",
        "def get_date_by_delta(dt, delta):\n",
        "  download_start_dt = datetime.datetime.strptime(dt, '%Y-%m-%d')\n",
        "  delta = datetime.timedelta(days=delta)\n",
        "  download_start_dt = download_start_dt + delta\n",
        "  download_start_dt = download_start_dt.strftime('%Y-%m-%d')\n",
        "  return download_start_dt\n",
        "\n",
        "train_start_dt = \"2007-01-01\" # 训练开始时间\n",
        "train_end_dt = \"2020-12-31\"\n",
        "valid_start_dt = \"2021-01-01\" # 评测开始时间\n",
        "valid_end_dt = \"2022-12-31\" # 评测结束时间\n",
        "download_start_dt = get_date_by_delta(train_start_dt, -90)\n",
        "# train_end_dt = get_date_by_delta(valid_start_dt, -50)\n",
        "\n",
        "class MyDownloader:\n",
        "  def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "    self.start_date = start_date\n",
        "    self.end_date = end_date\n",
        "    self.ticker_list = ticker_list\n",
        "\n",
        "  def fetch_data(self, proxy=None, auto_adjust=True) -> pd.DataFrame:\n",
        "    data_df = pd.DataFrame()\n",
        "    for tic in self.ticker_list:\n",
        "      if auto_adjust:\n",
        "        temp_df = ts.pro_bar(ts_code=tic, adj='hfq', start_date=self.start_date, end_date=self.end_date)\n",
        "      else:\n",
        "        temp_df = ts.pro_bar(ts_code=tic, adj='None', start_date=self.start_date, end_date=self.end_date)\n",
        "      del temp_df['ts_code'],temp_df['pre_close'],temp_df['change'],temp_df['pct_chg'],temp_df['amount']\n",
        "      # temp_df = yf.download(tic, start=self.start_date, end=self.end_date, proxy=proxy\n",
        "      #                       , prepost=False, auto_adjust=auto_adjust)\n",
        "      temp_df[\"tic\"] = tic\n",
        "      data_df = data_df.append(temp_df)\n",
        "    data_df = data_df.reset_index(drop=True)\n",
        "    data_df.columns = [\n",
        "      \"date\",\n",
        "      \"open\",\n",
        "      \"high\",\n",
        "      \"low\",\n",
        "      \"close\",\n",
        "      \"volume\",\n",
        "      \"tic\"\n",
        "    ]\n",
        "    data_df[\"date\"] = pd.to_datetime(data_df['date'], format=\"%Y%m%d\")\n",
        "    data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "    data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "    data_df.drop_duplicates(subset=['open','high','low','close','volume','tic'], keep='first', inplace=True)\n",
        "    data_df.drop(data_df[data_df['volume']==0.0].index, inplace=True)\n",
        "    data_df.dropna(inplace=True)\n",
        "    # data_df.drop(data_df[data_df['low'] == data_df['high']].index, inplace=True)\n",
        "    data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "    print(data_df.shape)\n",
        "    return data_df\n",
        "\n",
        "\n",
        "df = MyDownloader(start_date = download_start_dt, end_date = valid_end_dt, ticker_list = cnstock).fetch_data(auto_adjust=True)\n",
        "\n",
        "df.sort_values(['date','tic'],ignore_index=True).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmKZXAsk9TkJ"
      },
      "source": [
        "# 特征抽取"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import talib\n",
        "\n",
        "\n",
        "\n",
        "class MyFeatureEngineer(FeatureEngineer):\n",
        "  def add_user_defined_feature(self, data):\n",
        "    df = data.copy()\n",
        "    df['vwap'] = u.vwap(df)\n",
        "    df['returns'] = u.returns(df)   \n",
        "    unavailable = [48,53,56,57,58,59,63,67,69,70,76,79,80,82,83,87,89,90,91,93,97,100]\n",
        "    for n in range(101):\n",
        "      if n+1 in unavailable:\n",
        "        continue\n",
        "      name = 'alpha{}'.format(n+1)\n",
        "      func = 'fg.{}'.format(name)\n",
        "      temp_func = eval(func)\n",
        "      df[name] = temp_func(df)\n",
        "\n",
        "      df[name][np.isinf(df[name])] = 0.0\n",
        "    del df['vwap'], df['returns']\n",
        "    return df\n",
        "\n",
        "test_fe = MyFeatureEngineer(\n",
        "    use_technical_indicator=False,\n",
        "    use_vix=False,\n",
        "    use_turbulence=False,\n",
        "    user_defined_feature=True\n",
        ")\n",
        "processed_full = test_fe.preprocess_data(df)\n",
        "processed_full = processed_full[processed_full['date']>=train_start_dt].reset_index(drop=True)\n",
        "processed_full"
      ],
      "metadata": {
        "id": "t_05tJD8BZZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 标准化\n",
        "indicator_list = processed_full.columns[8::].values.tolist()\n",
        "print(len(indicator_list))\n",
        "print(indicator_list)\n",
        "\n",
        "for indicator in indicator_list:\n",
        "  processed_full[indicator] = (processed_full[indicator] - processed_full[(processed_full['date']>train_start_dt) & (processed_full['date']<train_end_dt)][indicator].mean())/processed_full[(processed_full['date']>train_start_dt) & (processed_full['date']<train_end_dt)][indicator].std(ddof=0)\n",
        "\n",
        "# processed_full.loc[:,indicator_list] = processed_full.loc[:,indicator_list].apply(zscore)\n",
        "processed_full"
      ],
      "metadata": {
        "id": "gfTqMd6LwD_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noadjust_df = MyDownloader(start_date = download_start_dt, end_date = valid_end_dt, ticker_list = cnstock).fetch_data(auto_adjust=False)\n",
        "noadjust_df.sort_values(['date','tic'],ignore_index=True).head()\n",
        "\n",
        "processed_full = pd.merge(noadjust_df, processed_full, on=['date', 'tic'], suffixes=['', '_tmp'])\n",
        "del processed_full['open_tmp'],processed_full['high_tmp'],processed_full['low_tmp']\n",
        "del processed_full['close_tmp'],processed_full['volume_tmp'],processed_full['day_tmp']\n",
        "processed_full"
      ],
      "metadata": {
        "id": "vXFFPkDiSGuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_full[processed_full.isnull().values].tail().T"
      ],
      "metadata": {
        "id": "DoHKswx70Wut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP9mQ40IqUvJ"
      },
      "outputs": [],
      "source": [
        "processed_full.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXTxTR0-1PUa"
      },
      "source": [
        "# RL环境env\n",
        "\n",
        "state = [资金分布， 特征]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXOh7gre2i2C"
      },
      "outputs": [],
      "source": [
        "class MyTradeEnv(StockTradingEnv):\n",
        "\n",
        "  def __init__(\n",
        "          self,\n",
        "          df,\n",
        "          stock_dim,\n",
        "          initial_amount,\n",
        "          buy_cost_pct,\n",
        "          sell_cost_pct,\n",
        "          state_space,\n",
        "          n_action_space,\n",
        "          reward_scaling,\n",
        "          tech_indicator_list,\n",
        "          ncpu,\n",
        "          hmax,\n",
        "          make_plots=False,\n",
        "          print_verbosity=10,\n",
        "          day=0,\n",
        "          initial=True,\n",
        "          model_name=\"\",\n",
        "          mode=\"\",\n",
        "          iteration=\"\",\n",
        "          n_invalid_actions=0):\n",
        "    self.day = day\n",
        "    self.df = df\n",
        "    self.stock_dim = stock_dim\n",
        "    self.initial_amount = initial_amount\n",
        "    self.buy_cost_pct = buy_cost_pct\n",
        "    self.sell_cost_pct = sell_cost_pct\n",
        "    self.state_space = state_space\n",
        "    self.n_action_space = n_action_space\n",
        "    self.tech_indicator_list = tech_indicator_list\n",
        "    self.reward_scaling = reward_scaling\n",
        "    self.ncpu = ncpu\n",
        "    self.hmax = hmax\n",
        "\n",
        "    self.n_invalid_actions = n_invalid_actions\n",
        "    self.possible_actions = np.arange(self.n_action_space)\n",
        "    self.invalid_actions: List[int] = []\n",
        "\n",
        "    self.action_space = spaces.Discrete(self.n_action_space)\n",
        "    # self.action_space = spaces.Box(low=-1, high=1, shape=(self.n_action_space,))\n",
        "    self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_space,))\n",
        "    self.data = self.df.loc[self.day, :]\n",
        "    self.terminal = False\n",
        "    self.make_plots = make_plots\n",
        "    self.print_verbosity = print_verbosity\n",
        "    self.initial = initial\n",
        "    self.model_name = model_name\n",
        "    self.mode = mode\n",
        "    self.iteration = iteration\n",
        "    self.state = self._initiate_state()\n",
        "    self.reward = 0\n",
        "    self.cost = 0\n",
        "    self.trades = 0\n",
        "    self.episode = 0\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    self.rewards_memory = []\n",
        "    self.actions_memory = []\n",
        "    self.date_memory = [self._get_date()]\n",
        "    self.max_total_assets = 0\n",
        "    self._seed()\n",
        "\n",
        "  def reset(self):\n",
        "    self.state = self._initiate_state()\n",
        "    self.asset_memory = [self.initial_amount]\n",
        "    self.day = 0\n",
        "    self.data = self.df.loc[self.day, :]\n",
        "    self.cost = 0\n",
        "    self.trades = 0\n",
        "    self.terminal = False\n",
        "    self.rewards_memory = []\n",
        "    self.actions_memory = []\n",
        "    self.date_memory = [self._get_date()]\n",
        "    self.episode += 1\n",
        "    self.max_total_assets = 0\n",
        "    self.possible_actions = np.arange(self.n_action_space)\n",
        "    self.invalid_actions: List[int] = []\n",
        "    return self.state\n",
        "\n",
        "  def action_masks(self):\n",
        "    action_masks = [action not in self.invalid_actions for action in self.possible_actions]\n",
        "    if self.mode == 'test':\n",
        "      print(\"action_masks:\", action_masks)\n",
        "    return action_masks\n",
        "\n",
        "  def update_action_masks(self):\n",
        "    account = round(self.state[0]/0.2) + 5\n",
        "    invalid_actions = []\n",
        "    for i in range(11):\n",
        "      if i+account >= 10 and i+account<=15:\n",
        "        continue\n",
        "      invalid_actions.append(i)\n",
        "    self.invalid_actions = np.array(invalid_actions)\n",
        "    if self.mode == 'test':\n",
        "      print(\"invalid_actions:\", self.invalid_actions, \" self.state[0]: \", self.state[0])\n",
        "\n",
        "  def _sell_stock(self, index, action):\n",
        "    # 可用股数\n",
        "    available_share = self.share_list[index]\n",
        "    # 卖出价\n",
        "    sell_price = self.price_list[index]\n",
        "\n",
        "    if available_share <= 0:\n",
        "      return 0\n",
        "    if sell_price <= 0:\n",
        "      return 0\n",
        "\n",
        "    # 计划卖出总金额 = 比例（abs（action））*帐号总金额\n",
        "    pred_sell_amount = abs(action) * self.hmax\n",
        "    # 卖出股数\n",
        "    pred_sell_num_shares = 100 * (pred_sell_amount // (sell_price * 100))\n",
        "    if self.mode == 'test':\n",
        "      print(\"sell--stock_dim: \", index, \" pred_sell_num_shares: \", pred_sell_num_shares, \" available_share: \", available_share, \" sell_price: \", sell_price)\n",
        "    sell_num_shares = min(pred_sell_num_shares, available_share)\n",
        "    # 金额\n",
        "    commision = min(5, sell_price * sell_num_shares * self.sell_cost_pct)\n",
        "    sell_amount = (sell_price * sell_num_shares * 0.999) - commision\n",
        "\n",
        "    # 修改状态\n",
        "    self.cash += sell_amount\n",
        "    self.share_list[index] -= sell_num_shares\n",
        "    self.cost += (sell_price * sell_num_shares * self.sell_cost_pct)\n",
        "    self.trades += 1\n",
        "    return sell_num_shares\n",
        "\n",
        "  def _buy_stock(self, index, action):\n",
        "    buy_price = self.price_list[index]\n",
        "    if buy_price <= 0:\n",
        "      return 0\n",
        "\n",
        "    # 可以买的上限\n",
        "    available_amount = self.cash // buy_price\n",
        "    available_amount = (available_amount // 100) * 100\n",
        "    if available_amount == 0:\n",
        "      return 0\n",
        "\n",
        "    # 计划买\n",
        "    pred_buy_amount = abs(action) * self.hmax\n",
        "    pred_buy_num_shares = 100 * (pred_buy_amount // (buy_price * 100))\n",
        "    buy_num_shares = min(pred_buy_num_shares, available_amount)\n",
        "    if self.mode == 'test':\n",
        "      print(\"buy--stock_dim: \", index, \" pred_buy_num_shares: \", pred_buy_num_shares, \" available_amount: \", available_amount, \" buy cash: \", self.cash, \" buy price: \", buy_price)\n",
        "\n",
        "    # 交易金额\n",
        "    commision = min(5, buy_price * buy_num_shares * self.sell_cost_pct)\n",
        "    buy_amount = buy_price * buy_num_shares + commision\n",
        "\n",
        "    # 修改状态\n",
        "    self.cash -= buy_amount\n",
        "    self.share_list[index] += buy_num_shares\n",
        "    self.cost += buy_price * buy_num_shares * self.buy_cost_pct\n",
        "    self.trades += 1\n",
        "    return buy_num_shares\n",
        "\n",
        "  def step(self, actions):\n",
        "    if self.mode == 'test':\n",
        "      print(\"\")\n",
        "    # 判断是否合法\n",
        "    actions = np.array([actions*0.2-1])\n",
        "    self.fund_rate = 0\n",
        "\n",
        "    # 是否是数据的最后一天\n",
        "    self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
        "    if self.terminal:\n",
        "      if self.make_plots:\n",
        "        self._make_plot()\n",
        "\n",
        "      # 存储最后一天的action\n",
        "      self._update_actions(actions)\n",
        "      self._save_action_memory_at_last()\n",
        "      self._save_asset_memory_at_last()\n",
        "\n",
        "      end_total_asset = self.cash + sum(np.array(self.price_list)* np.array(self.share_list))\n",
        "      tot_reward = end_total_asset - self.initial_amount\n",
        "      df_total_value = pd.DataFrame(self.asset_memory)\n",
        "      df_total_value.columns = [\"account_value\"]\n",
        "      df_total_value[\"date\"] = self.date_memory\n",
        "      df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "      sharpe = self.get_sharpe()\n",
        "      df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "      df_rewards.columns = [\"account_rewards\"]\n",
        "      df_rewards[\"date\"] = self.date_memory[:-1]\n",
        "      self.fund_rate = tot_reward * (250/self.day) * 100/ self.initial_amount\n",
        "      self.reward = 0\n",
        "      # if self.episode % self.print_verbosity == 0:\n",
        "      #   print(f\"day: {self.day}, episode: {self.episode}\")\n",
        "      #   print(f\"fund rate yearly: {self.fund_rate:0.2f}%\")\n",
        "      #   print(f\"total_reward: {tot_reward:0.2f}\")\n",
        "      #   print(f\"total_cost: {self.cost:0.2f}\")\n",
        "      #   print(f\"total_trades: {self.trades}\")\n",
        "      #   if df_total_value[\"daily_return\"].std() != 0:\n",
        "      #       print(f\"Sharpe: {sharpe:0.3f}\")\n",
        "      #   print(\"=================================\")\n",
        "\n",
        "    else:\n",
        "      begin_total_asset = self.cash + sum(np.array(self.close_price_list)* np.array(self.share_list))\n",
        "      yesterday_close = np.array(self.close_price_list)\n",
        "      yesterday_share = np.array(self.share_list)\n",
        "      yesterday_cash = self.cash\n",
        "      # print(self.close_price_list, begin_total_asset)\n",
        "      # 修改价格到下一天\n",
        "      self.day += 1\n",
        "      self.data = self.df.loc[self.day, :]\n",
        "      self.state = self._update_state()\n",
        "\n",
        "      # 使用第2天开盘价，actions执行交易\n",
        "      self._update_actions(actions)\n",
        "      end_total_asset = self.cash + sum(np.array(self.close_price_list)* np.array(self.share_list))\n",
        "      today_close = np.array(self.close_price_list)\n",
        "      today_share = np.array(self.share_list)\n",
        "      today_cash = self.cash\n",
        "      self.asset_memory.append(end_total_asset)\n",
        "      self.date_memory.append(self._get_date())\n",
        "\n",
        "      # 计算reward\n",
        "      # self.reward = self.get_reward(end_total_asset, begin_total_asset, self.day)\n",
        "      self.reward = self._get_reward(yesterday_close, yesterday_share, yesterday_cash, today_close, today_share, today_cash)\n",
        "      self.rewards_memory.append(self.reward)\n",
        "      # print(self.close_price_list, end_total_asset, self.reward)\n",
        "\n",
        "    total_asset = self.cash + sum(np.array(self.price_list)* np.array(self.share_list))\n",
        "    for i in range(self.stock_dim):\n",
        "      self.state[i] = self.price_list[i] * self.share_list[i] / total_asset\n",
        "    self.update_action_masks()\n",
        "    return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "  def _get_reward(self, yesterday_close, yesterday_share, yesterday_cash, today_close, today_share, today_cash):\n",
        "    if self.day == 1:\n",
        "      if self.mode == 'test':\n",
        "        print(yesterday_close, yesterday_share, yesterday_cash, today_close, today_share, today_cash, 0)\n",
        "      return 0\n",
        "\n",
        "    begin = yesterday_cash + sum(yesterday_share * yesterday_close)\n",
        "    end = today_cash + sum(today_share * today_close)\n",
        "    delta_share = np.negative(today_share - yesterday_share)\n",
        "    delta_price = today_close - yesterday_close\n",
        "    delta_assets = sum(-delta_share * delta_price)\n",
        "\n",
        "    # assets = end - begin + delta_assets\n",
        "    assets = end - begin\n",
        "    reward = 100 * assets / self.initial_amount\n",
        "    if self.mode == 'test':\n",
        "      print(yesterday_close, yesterday_share, yesterday_cash, today_close, today_share, today_cash, begin, end, delta_assets, reward)\n",
        "    return reward \n",
        "\n",
        "  def get_sharpe(self):\n",
        "    df_total_value = pd.DataFrame(self.asset_memory)\n",
        "    df_total_value.columns = [\"account_value\"]\n",
        "    df_total_value[\"date\"] = self.date_memory\n",
        "    df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "\n",
        "    sharpe = 0.0\n",
        "    if df_total_value[\"daily_return\"].std() != 0:\n",
        "      sharpe = (\n",
        "        (250 ** 0.5)\n",
        "        * df_total_value[\"daily_return\"].mean()\n",
        "        / df_total_value[\"daily_return\"].std()\n",
        "      )\n",
        "    return sharpe\n",
        "\n",
        "  def _update_actions(self, actions):\n",
        "    if self.mode == 'test':\n",
        "      print(\"actions \", actions)\n",
        "    argsort_actions = np.argsort(actions)\n",
        "    if self.mode == 'test':\n",
        "      print(\"argsort_actions \", argsort_actions)\n",
        "\n",
        "    sell_index = argsort_actions[: np.where((actions < 0))[0].shape[0]]\n",
        "    buy_index = argsort_actions[::-1][: np.where((actions > 0))[0].shape[0]]\n",
        "    if self.mode == 'test':\n",
        "      print(\"sell_index: \", sell_index)\n",
        "      print(\"buy_index: \", buy_index)\n",
        "\n",
        "    for index in sell_index:\n",
        "      actions[index] = self._sell_stock(index, actions[index]) * (-1)\n",
        "\n",
        "    for index in buy_index:\n",
        "      actions[index] = self._buy_stock(index, actions[index])\n",
        "    if self.mode == 'test':\n",
        "      print(\"b_s_actions \", actions)\n",
        "    self.actions_memory.append(actions)\n",
        "\n",
        "  def get_sb_env(self):\n",
        "    if self.ncpu == 1:\n",
        "      e = DummyVecEnv([lambda: self])\n",
        "      obs = e.reset()\n",
        "      return e, obs\n",
        "    else:\n",
        "      e = SubprocVecEnv([lambda: self for i in range(self.ncpu)])\n",
        "      obs = e.reset()\n",
        "      return e, obs\n",
        "\n",
        "  def _initiate_state(self):\n",
        "    if len(self.df.tic.unique()) > 1:\n",
        "      # for multiple stock\n",
        "      state = (\n",
        "          [0] * self.stock_dim\n",
        "          + sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list],[],)\n",
        "      )\n",
        "      self.cash = self.initial_amount\n",
        "      self.price_list = self.data.open.values.tolist()\n",
        "      self.close_price_list = self.data.close.values.tolist()\n",
        "      self.share_list = [0] * self.stock_dim\n",
        "    else:\n",
        "      # for single stock\n",
        "      state = (\n",
        "          [0] * self.stock_dim\n",
        "          + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
        "      )\n",
        "      self.cash = self.initial_amount\n",
        "      self.price_list = [self.data.open]\n",
        "      self.close_price_list = [self.data.close]\n",
        "      self.share_list = [0] * self.stock_dim\n",
        "    return state\n",
        "\n",
        "  def _update_state(self):\n",
        "    if len(self.df.tic.unique()) > 1:\n",
        "      # for multiple stock\n",
        "      state = (\n",
        "        list(self.state[0: self.stock_dim])\n",
        "        + sum([self.data[tech].values.tolist() for tech in self.tech_indicator_list],[],)\n",
        "      )\n",
        "      self.price_list = self.data.open.values.tolist()\n",
        "      self.close_price_list = self.data.close.values.tolist()\n",
        "\n",
        "    else:\n",
        "      # for single stock\n",
        "      state = (\n",
        "        list(self.state[0: self.stock_dim])\n",
        "        + sum([[self.data[tech]] for tech in self.tech_indicator_list], [])\n",
        "      )\n",
        "      self.price_list = [self.data.open]\n",
        "      self.close_price_list = [self.data.close]\n",
        "    return state\n",
        "\n",
        "  def _save_action_memory_at_last(self):\n",
        "    if len(self.df.tic.unique()) > 1:\n",
        "      date_list = self.date_memory\n",
        "      df_date = pd.DataFrame(date_list)\n",
        "      df_date.columns = [\"date\"]\n",
        "\n",
        "      action_list = self.actions_memory\n",
        "      df_actions = pd.DataFrame(action_list)\n",
        "      df_actions.columns = self.data.tic.values\n",
        "      df_actions.index = df_date.date\n",
        "      self.df_actions = df_actions\n",
        "    else:\n",
        "      date_list = self.date_memory\n",
        "      action_list = self.actions_memory\n",
        "      df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
        "      self.df_actions = df_actions\n",
        "\n",
        "  def _save_asset_memory_at_last(self):\n",
        "    date_list = self.date_memory\n",
        "    asset_list = self.asset_memory\n",
        "    self.df_account_value = pd.DataFrame(\n",
        "        {\"date\": date_list, \"account_value\": asset_list}\n",
        "    )\n",
        "    \n",
        "  def save_asset_memory(self):\n",
        "    return self.df_account_value\n",
        "\n",
        "  def save_action_memory(self):\n",
        "    return self.df_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frcjoISC1U8O"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## network"
      ],
      "metadata": {
        "id": "Z-PLs5p8RHG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
        "\n",
        "import gym\n",
        "import torch as th\n",
        "from torch import nn\n",
        "\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
        "\n",
        "\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    feature_dim: int,\n",
        "    last_layer_dim_pi: int = 16,\n",
        "    last_layer_dim_vf: int = 16,\n",
        "  ):\n",
        "    super(CustomNetwork, self).__init__()\n",
        "\n",
        "    self.latent_dim_pi = last_layer_dim_pi\n",
        "    self.latent_dim_vf = last_layer_dim_vf\n",
        "\n",
        "    # Policy network\n",
        "    self.policy_net = nn.Sequential(\n",
        "        nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
        "    )\n",
        "    # Value network\n",
        "    self.value_net = nn.Sequential(\n",
        "        nn.Linear(feature_dim, last_layer_dim_vf), nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
        "    return self.policy_net(features), self.value_net(features)\n",
        "\n",
        "  def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
        "    return self.policy_net(features)\n",
        "\n",
        "  def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
        "    return self.value_net(features)\n",
        "\n",
        "\n",
        "class CustomActorCriticPolicy(MaskableActorCriticPolicy):\n",
        "  def _build_mlp_extractor(self) -> None:\n",
        "    self.mlp_extractor = CustomNetwork(self.features_dim)\n"
      ],
      "metadata": {
        "id": "ynMzhXYf0yhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## callback"
      ],
      "metadata": {
        "id": "LHSOHpyRQh6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sb3_contrib.common.maskable.callbacks import MaskableEvalCallback\n",
        "from stable_baselines3.common.vec_env import sync_envs_normalization\n",
        "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
        "\n",
        "class MyMaskableEvalCallback(MaskableEvalCallback):\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "      # Sync training and eval env if there is VecNormalize\n",
        "      sync_envs_normalization(self.training_env, self.eval_env)\n",
        "\n",
        "      # Reset success rate buffer\n",
        "      self._is_success_buffer = []\n",
        "\n",
        "      e_trade_gym = MyTradeEnv(df=trade, **env_kwargs)\n",
        "      e_trade_gym.seed(seed)\n",
        "\n",
        "\n",
        "      test_env, test_obs = e_trade_gym.get_sb_env()\n",
        "      test_env = VecNormalize(test_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
        "      test_env.training = False\n",
        "      test_env.norm_reward = False\n",
        "\n",
        "      episode_rewards, episode_lengths = evaluate_policy(self.model, test_env, n_eval_episodes=1)\n",
        "\n",
        "      mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)\n",
        "      mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)\n",
        "      self.last_mean_reward = mean_reward\n",
        "\n",
        "      if self.verbose > 0:\n",
        "        print(f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "      # Add to current Logger\n",
        "      self.logger.record(\"eval/mean_reward\", float(mean_reward))\n",
        "\n",
        "      if len(self._is_success_buffer) > 0:\n",
        "        success_rate = np.mean(self._is_success_buffer)\n",
        "        if self.verbose > 0:\n",
        "          print(f\"Success rate: {100 * success_rate:.2f}%\")\n",
        "        self.logger.record(\"eval/success_rate\", success_rate)\n",
        "\n",
        "      # Dump log so the evaluation results are printed with the correct timestep\n",
        "      self.logger.record(\"time/total timesteps\", self.num_timesteps, exclude=\"tensorboard\")\n",
        "      self.logger.dump(self.num_timesteps)\n",
        "\n",
        "      if mean_reward > self.best_mean_reward:\n",
        "        if self.verbose > 0:\n",
        "          print(\"New best mean reward!\")\n",
        "        if self.best_model_save_path is not None:\n",
        "          self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))\n",
        "        self.best_mean_reward = mean_reward\n",
        "        # Trigger callback if needed\n",
        "        if self.callback is not None:\n",
        "          return self._on_event()\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "KMLpevYHQyjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "0hjEhV-HQlCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sb3_contrib import MaskablePPO\n",
        "from stable_baselines3.common.type_aliases import MaybeCallback\n",
        "from stable_baselines3.common.vec_env import VecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback, CallbackList, ConvertCallback\n",
        "\n",
        "class MyMaskablePPO(MaskablePPO):\n",
        "  def _init_callback(\n",
        "    self,\n",
        "    callback: MaybeCallback,\n",
        "    eval_env: Optional[VecEnv] = None,\n",
        "    eval_freq: int = 10000,\n",
        "    n_eval_episodes: int = 5,\n",
        "    log_path: Optional[str] = None,\n",
        "    use_masking: bool = True,\n",
        "  ) -> BaseCallback:\n",
        "\n",
        "    if isinstance(callback, list):\n",
        "      callback = CallbackList(callback)\n",
        "\n",
        "    # Convert functional callback to object\n",
        "    if not isinstance(callback, BaseCallback):\n",
        "      callback = ConvertCallback(callback)\n",
        "\n",
        "    callback.init_callback(self)\n",
        "    return callback"
      ],
      "metadata": {
        "id": "6rjfyKFHQzCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "YqMnk1I_RMeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = data_split(processed_full, train_start_dt, train_end_dt)\n",
        "trade = data_split(processed_full, valid_start_dt, valid_end_dt)\n",
        "print(len(train))\n",
        "print(len(trade))\n",
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension + len(indicator_list)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "id": "OikwFTWXP7yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env_kwargs = {\n",
        "  \"initial_amount\": 100000, \n",
        "  \"buy_cost_pct\": 0.00025,\n",
        "  \"sell_cost_pct\": 0.00025,\n",
        "  \"state_space\": state_space, \n",
        "  \"stock_dim\": stock_dimension, \n",
        "  \"tech_indicator_list\": indicator_list, \n",
        "  \"n_action_space\": 11,\n",
        "  \"reward_scaling\": 1,\n",
        "  \"ncpu\": 1,\n",
        "  \"hmax\": 100000, \n",
        "  # \"mode\": \"test\"\n",
        "}\n",
        "\n",
        "e_train_gym = MyTradeEnv(df=train, **env_kwargs)\n",
        "e_train_gym.seed(seed)\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "env_train = VecNormalize(env_train, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
        "\n",
        "\n",
        "model_kwargs = {\n",
        "  \"n_steps\": 2048,\n",
        "  \"ent_coef\": 0.01,\n",
        "  \"learning_rate\": 0.00025,\n",
        "  \"batch_size\": 128,\n",
        "}\n",
        "\n",
        "\n",
        "#########\n",
        "# trained_model.save(\"./model\")"
      ],
      "metadata": {
        "id": "jiPHSnmd1OzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 迭代找最优\n",
        "from finrl.agents.stablebaselines3.models import TensorboardCallback\n",
        "\n",
        "# train\n",
        "model_name = \"ppo\"\n",
        "\n",
        "best_seed = 0\n",
        "best_reward = -100\n",
        "for seed in range(100,200):\n",
        "  # test\n",
        "  trained_model = MyMaskablePPO(policy=CustomActorCriticPolicy,\n",
        "            env=env_train,\n",
        "            tensorboard_log=\"tb_log\",\n",
        "            verbose=0,\n",
        "            seed=seed,\n",
        "            create_eval_env=True,\n",
        "            **model_kwargs,\n",
        "          )\n",
        "  trained_model.learn(total_timesteps=10240 * 20,\n",
        "            tb_log_name=model_name,\n",
        "            callback=[\n",
        "              TensorboardCallback(),\n",
        "              MyMaskableEvalCallback(env_train,n_eval_episodes=1,eval_freq=10240*1\n",
        "                          ,log_path=\"new_eval_log_path_{}\".format(seed)\n",
        "                          ,best_model_save_path=\"new_eval_log_path_{}\".format(seed))\n",
        "            ],\n",
        "          )\n",
        "  # evaluate\n",
        "  e_trade_gym = MyTradeEnv(df=trade, **env_kwargs)\n",
        "  e_trade_gym.seed(seed)\n",
        "  test_env, test_obs = e_trade_gym.get_sb_env()\n",
        "  test_env = VecNormalize(test_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
        "  test_env.training = False\n",
        "  test_env.norm_reward = False\n",
        "\n",
        "  model_path = \"new_eval_log_path_{}/best_model.zip\".format(seed)\n",
        "  trained = MyMaskablePPO.load(model_path)\n",
        "  mean_reward, std_reward = evaluate_policy(trained, test_env, n_eval_episodes=1)\n",
        "  if mean_reward > best_reward:\n",
        "    best_reward = mean_reward\n",
        "    best_seed = seed\n",
        "  print(\"best_seed \", best_seed, \"best_reward \", best_reward)\n",
        "  print(\"next_round\")"
      ],
      "metadata": {
        "id": "Js5Byks8AY4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9eT7XjE1bqP"
      },
      "source": [
        "# 回测"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S77rNM_2stow"
      },
      "outputs": [],
      "source": [
        "# model_path = \"./model\"\n",
        "seed = 0\n",
        "# model_path = \"new_eval_log_path_{}/best_model.zip\".format(seed)\n",
        "model_path = \"best_model.zip\"\n",
        "trained = MyMaskablePPO.load(model_path)\n",
        "e_trade_gym = MyTradeEnv(df=trade, **env_kwargs)\n",
        "e_trade_gym.seed(seed)\n",
        "\n",
        "\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()\n",
        "# test_env = VecNormalize.load(\"./env.pkl\", test_env)\n",
        "test_env = VecNormalize(test_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
        "test_env.training = False\n",
        "test_env.norm_reward = False\n",
        "\n",
        "account_memory = []\n",
        "actions_memory = []\n",
        "rewards_list = []\n",
        "test_env.reset()\n",
        "for i in range(len(e_trade_gym.df.index.unique())):\n",
        "  action_masks = e_trade_gym.action_masks()\n",
        "  action, _states = trained.predict(test_obs,deterministic=True,action_masks=action_masks)\n",
        "  test_obs, rewards, dones, info = test_env.step(action)\n",
        "  rewards_list.append(rewards[0])\n",
        "  if dones[0]:\n",
        "    actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
        "    account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
        "    print(\"hit end!\")\n",
        "    break\n",
        "\n",
        "df_account_value, df_actions = account_memory[0], actions_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e_trade_gym = MyTradeEnv(df=trade, **env_kwargs)\n",
        "e_trade_gym.seed(seed)\n",
        "\n",
        "\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()\n",
        "test_env = VecNormalize(test_env, norm_obs=True, norm_reward=False, clip_obs=10.)\n",
        "test_env.training = False\n",
        "test_env.norm_reward = False\n",
        "\n",
        "# mean_reward, std_reward = evaluate_policy(trained, test_env, n_eval_episodes=10)\n",
        "mean_reward, std_reward = evaluate_policy(trained, test_env, n_eval_episodes=1)\n",
        "mean_reward"
      ],
      "metadata": {
        "id": "-6xYg2acIrcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_account_value"
      ],
      "metadata": {
        "id": "fhJIhzyt_Jqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aKxsCvGtEYX"
      },
      "outputs": [],
      "source": [
        "\n",
        "display;\n",
        "if len(cnstock) != 1:\n",
        "  print(df_actions.sum())\n",
        "  print(df_account_value.tail(1))\n",
        "  display = df_actions.cumsum().drop_duplicates()\n",
        "  display.index = pd.to_datetime(display.index)\n",
        "else:\n",
        "  df_actions['actions'] = df_actions['actions'].apply(lambda x: x[0])\n",
        "  display = df_actions.copy();\n",
        "  display['actions'] = display['actions'].cumsum()\n",
        "  display = display.set_index(['date'],drop=True)\n",
        "  df_actions = df_actions.set_index(['date'],drop=True)\n",
        "display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwBEl7Em5tBV"
      },
      "source": [
        "## pyfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MGpXFYBs4aU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "baseline_ticker = \"000001.ss\"\n",
        "if len(cnstock) == 1:\n",
        "  baseline_ticker = cnstock[0]\n",
        "\n",
        "backtest_plot(df_account_value, \n",
        "      baseline_ticker = baseline_ticker, \n",
        "      baseline_start = valid_start_dt,\n",
        "      baseline_end = valid_end_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAdxV1b5yCo"
      },
      "source": [
        "## matplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zf5JnbgC6B4"
      },
      "outputs": [],
      "source": [
        "def plot(tradedata,actionsdata,ticker):    \n",
        "  fig=plt.figure(figsize=(12, 6))\n",
        "  ax=fig.add_subplot(211) \n",
        "  df_plot = pd.merge(left=tradedata ,right=actionsdata,on='date',how='inner')\n",
        "  if len(cnstock) == 1:\n",
        "    plot_df = df_plot.loc[df_plot['tic']==ticker].loc[:,['date','tic','open','actions']].reset_index()\n",
        "  else:\n",
        "    plot_df = df_plot.loc[df_plot['tic']==ticker].loc[:,['date','tic','open',ticker]].reset_index()\n",
        "\n",
        "  print(plot_df)\n",
        "  plot_df['datetime'] = pd.to_datetime(plot_df['date'], format=\"%Y-%m-%d\")\n",
        "  ax.plot(plot_df.datetime, plot_df['open'], label=ticker)\n",
        "  locator = mdates.MonthLocator()\n",
        "  ax.xaxis.set_major_locator(locator)\n",
        "  fig.autofmt_xdate()\n",
        "  # 主图 \n",
        "  if len(cnstock) == 1:\n",
        "    ax.plot(plot_df.loc[plot_df['actions']>0].datetime, plot_df['open'][plot_df['actions']>0], label='Buy', linewidth=0, marker='^', c='g')\n",
        "    ax.plot(plot_df.loc[plot_df['actions']<0].datetime, plot_df['open'][plot_df['actions']<0], label='Sell', linewidth=0, marker='v', c='r')\n",
        "  else:\n",
        "    ax.plot(plot_df.loc[plot_df[ticker]>0].datetime, plot_df['open'][plot_df[ticker]>0], label='Buy', linewidth=0, marker='^', c='g')\n",
        "    ax.plot(plot_df.loc[plot_df[ticker]<0].datetime, plot_df['open'][plot_df[ticker]<0], label='Sell', linewidth=0, marker='v', c='r')\n",
        "  # 副图\n",
        "  if len(cnstock) == 1:\n",
        "    ax2 = plt.subplot(212, sharex=ax)\n",
        "    ax2.plot(pd.to_datetime(display.index), display['actions'])\n",
        "  else:\n",
        "    ax2 = plt.subplot(212, sharex=ax)\n",
        "    ax2.plot(display.index, display[ticker])\n",
        "  plt.legend(loc='best')\n",
        "  plt.grid(True)\n",
        "  plt.title(ticker +'__'+plot_df['date'].min()+'___'+plot_df['date'].max())\n",
        "  plt.show()\n",
        "  if len(cnstock) == 1:\n",
        "    print(plot_df.loc[plot_df['actions']!=0])\n",
        "  else:\n",
        "    print(plot_df.loc[plot_df[ticker]!=0])\n",
        "\n",
        "for tic in cnstock:\n",
        "  plot(trade,df_actions,tic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot = pd.merge(left=trade ,right=df_actions,on='date',how='inner')\n",
        "df_plot.loc[df_plot['tic']==cnstock[0]].loc[:,['date','tic','open','actions']].reset_index()"
      ],
      "metadata": {
        "id": "FBJTqjVg9ky7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "rl.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAUIyN8IqRRXTmkc/BPkoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}